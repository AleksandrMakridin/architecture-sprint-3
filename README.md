# Sprint 3
## Пояснения перед работой, лично мое мнение, могу ошибаться. 

## Пояснение 1 

Задание немного противоречит само себе в части устройств.
Пользователь самостоятельно выбирает необходимые ему модули умного дома. Компания но поддерживает подключение к экосистеме устройств партнёров.

Но при этом. Модули управления приборами и сами приборы (устройства) должны быть максимально готовы к использованию и продаваться в отдельных комплектах для удобной покупки и подключения.

Т.е. это либо стандартизированные наборы (расширяемые количественно однотипными моделями), например комплекты безопасность, отопление, сантехника (протечки и подача воды), и т.п.
Или наборы из датчиков и контроллеров, которые могут объединяться в любые комплекты с помощью настроек (например наборы tuya ).

## Пояснение 2. 

Если рассматривать задачу, только как работу с готовыми комплектами, тогда данную задачу можно попробовать решить с помощью модульного подхода к программированию. Каждый модуль будет равен комплекту (например модуль безопасность – комплект безопасность).
Однако при неконтролируемом расширении (в задании указано, что пользователь сам может расширять комплекты. Ограничения не указаны) модули скорее всего получатся достаточно тяжелыми. Это частично решит поставленную задачу. Поэтому от данного решения нужно отказаться.

## Отмазки

Я не рассматриваю ситуацию с временным сохранением монолита в to be. Т.е. as-is монолит, to-be транзитная монолит + микросервисы, to-be целевая только микросервисы. Т.к. монолит в себе содержит условно только два домена, мониторинг температуры(можно было бы временно использовать), управление устройствами, и вот повесить все новые устройства на эту часть монолита без возможности масштабирования. В моем понимание, самоубийство.  А сохранение монолита только для управления температурой двойная работа.

Я не рассматриваю какую –то офлайн жизнь комплектов. Понятно, что она в реальной жизни должна быть. Но по условиям, должен быть канал для работы, и считаем, условно – он идеален, и никогда не падает. 

# Задание 1. Анализ и планирование
## 1.3 Определите домены и границы контекстов (AS-IS) 

На основе монолита можно выделить следующие домены:

1. Управление Устройствами (Device Management):
   - Включение/выключение отопления.
   - Контроль целевой температуры (выставление целевой температуры, отключение при достужении или поддержание целевой темпереатуры).
   - Таймер (напрмер запуск на полную при ночном тарифе, если отопление электрическое)

2. Мониторинг Температуры (Temperature Monitoring):
   - Получение текущей температуры.
   - Статистика температуры за период

Переиспользование. Выше описано, что в примере не рассматривается использование монолита в to-be.
Т.ч. сохраняются только название доменов и список функционала.

## 1.4. Проведите анализ архитектуры монолитного приложения (AS-IS)

### Плюсы монолита:
1. Простота разработки: Монолит проще разрабатывать, все находится в одном месте.
2. Целостность данных: Все данные хранятся в одной базе данных (возможно разделение на схемы), за целостностью данных следит единый PostgreSQL.

### Минусы монолита:
1. Сложность масштабирования: Монолитное приложение сложно масштабировать (только вертикально).
2. Сложность развития: Изменения влияют на всю систему. Из-за одной ошибки, может лечь все приложение.
3. Ограничение по развертывание: требуется перезапуск всего приложения.

### Дополнительный минус описанного в примере монолита (вернее реализованного подходу к интеграции).
Используется только синхронное взаимодействие.
Синхронная обработка запросов может привести к блокировкам и задержкам в системе. 



## 1.5. Визуализируйте контекст системы AS-IS. 
[схема](https://github.com/AleksandrMakridin/architecture-sprint-3/blob/sprint-3/sprint3task1.puml)






# Задание 2. Проектирование микросервисной архитектуры
## 2.1. Декомпозируйте приложение на микросервисы. TO-BE

Целевое решение будет состоять из нескольких микросервисов, каждый из которых будет отвечать за определенную функциональность. Т.е 1 микросервис - 1 функциональность.  
Взаимодействие (настраиваемое  - скрипты, интерфейс пользователя) этих сервисов позволит реализовать достаточно гибкую систему умного дома. 

## Здесь важно пояснить.

По факту можно провести более низкоуровневое дробление, т.е. взять за основу типы датчиков и устройств.
Тогда у нас получится:
Мониторинг температуры, мониторинг протечки, мониторинг состояния ворот и .т.п.
Управление температурой, водой, воротами и т.п.
В таком случае мы получим почти не убиваемое и гибчайшее, но очень сложное решение для умного дома.
Но, согласно условиям задания у нас команда состоит только из:
- Команда разработчиков - 5 человек.
- Команда DevOps - 2 человека. 
Реализация такими силами усложненного проекта не представляется возможным.
Поэтому исхожу из минимально возможного набора. В моем случае 1 человек - 1 микросервис.

1. Управление устройствами:
    - Включение/выключение отопления, освещения и т.п..
    - Установка целевой температуры, таймер включения и отключения.
    - Управление водоснабжением
    - Управление электричеством
    - Управление автоматическими воротами.

2. Мониторинг: (Важно. В данном случае Мониторинг подразумевает контроль всех датчиков умного дома, включая температуру.)
    - Получение данных о текущей состоянии с датчиков.
    - Хранение и анализ данных для отчетов.

3. Управление пользователями:
    - Регистрация, авторизация и аутентификация пользователей.
    - Управление профилями пользователей.

4. Сценарии (атоматизация, реализация тех самыех наборов умного дома из простейших датчиков и контроллеров):
    - Создание и управление автоматическими сценариями работы устройств.

5. Уведомления и отчетность:
    - Отправка уведомлений пользователям о состоянии устройств и выполнении сценариев, плюс итоговая отчетность - например в конце месяца отчет об электрозатратах и т.п..

### Основные микросервисы. TO-BE

1. Device Management Service:
    - Управление устройствами (Взаимодействие с устройствами через стандартные протоколы - согласно заданию).

2. Monitoring Service:
    - Получение и хранение данных.
    
3. User Service:
    - Регистрация, авторизация и аутентификация пользователей.Управление профилями пользователей.

4. Script Management Service:
    - Создание и управление автоматическими сценариями работы устройств.

5. Notification Service:
    - Отправка уведомлений пользователям.

## 2.2. Определите взаимодействия между. TO-BE


- API Gateway -  Маршрутизирует запросы к соответствующим микросервисам.
- Kafka -  Используется для асинхронного взаимодействия (отказываемся от синхронного взаимодействия, минуса состояния as-is) между микросервисами. 
- Базы данных - Оставляем PostgreSQL. Само собой каждый микросервис имеет свою собственную базу данных. 

## 2.3. Визуализируйте архитектуры:. TO-BE
## C4 — Уровень контейнеров (Containers). 
https://github.com/AleksandrMakridin/architecture-sprint-3/blob/sprint-3/sprint3task2.3.1Containers.puml


# Базовая настройка

## Запуск minikube

[Инструкция по установке](https://minikube.sigs.k8s.io/docs/start/)

```bash
minikube start
```

## Добавление токена авторизации GitHub

[Получение токена](https://github.com/settings/tokens/new)

```bash
kubectl create secret docker-registry ghcr --docker-server=https://ghcr.io --docker-username=<github_username> --docker-password=<github_token> -n default
```

## Установка API GW kusk

[Install Kusk CLI](https://docs.kusk.io/getting-started/install-kusk-cli)

```bash
kusk cluster install
```

## Смена адреса образа в helm chart

После того как вы сделали форк репозитория и у вас в репозитории отработал GitHub Action. Вам нужно получить адрес образа <https://github.com/><github_username>/architecture-sprint-3/pkgs/container/architecture-sprint-3

Он выглядит таким образом
```ghcr.io/<github_username>/architecture-sprint-3:latest```

Замените адрес образа в файле `helm/smart-home-monolith/values.yaml` на полученный файл:

```yaml
image:
  repository: ghcr.io/<github_username>/architecture-sprint-3
  tag: latest
```

## Настройка terraform

[Установите Terraform](https://yandex.cloud/ru/docs/tutorials/infrastructure-management/terraform-quickstart#install-terraform)

Создайте файл ~/.terraformrc

```hcl
provider_installation {
  network_mirror {
    url = "https://terraform-mirror.yandexcloud.net/"
    include = ["registry.terraform.io/*/*"]
  }
  direct {
    exclude = ["registry.terraform.io/*/*"]
  }
}
```

## Применяем terraform конфигурацию

```bash
cd terraform
terraform init
terraform apply
```

## Настройка API GW

```bash
kusk deploy -i api.yaml
```

## Проверяем работоспособность

```bash
kubectl port-forward svc/kusk-gateway-envoy-fleet -n kusk-system 8080:80
curl localhost:8080/hello
```

## Delete minikube

```bash
minikube delete
```
